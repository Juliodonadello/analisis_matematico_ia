{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKln7y0TSwP1"
   },
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "## El problema de la Recomendación\n",
    "\n",
    "Matemáticamente podemos expresar este problema como que queremos estimar \"los elementos faltantes\" de la matriz de ratings para $n$ usuarios y $m$ items $R \\in \\mathbb{R}^{n \\times m}$.\n",
    "\n",
    "Si consideramos a $\\mathcal{O}$ como el conjunto de los $(i,j)$ para los cuales sí se conoce el verdadero valor, estamos en un escenario en el que\n",
    "$$\n",
    "\\#(\\mathcal{O}) << n \\cdot m\n",
    "$$\n",
    "\n",
    "es decir, se conocen **tan pocos elementos** que no es factible \"completar\" la matriz utilizando métodos de *imputation* comunes.\n",
    "\n",
    "## El modelo de Matrix Factorization ([\"Funk-SVD\"](https://sifter.org/~simon/journal/20061211.html))\n",
    "\n",
    "Una forma de controlar la dimensionalidad y al mismo tiempo poder realizar predicciones es plantear un modelo de $k$ dimensiones donde se definen $U \\in \\mathbb{R}^{n \\times k}$ la matriz de *features de usuarios* y $V \\in \\mathbb{R}^{k \\times m}$ la matriz de *features de items*, y luego se plantea que\n",
    "$$\n",
    "R \\approx U \\cdot V\n",
    "$$\n",
    "\n",
    "De esta manera no sólo se tiene un gran control sobre la dimensionalidad del modelo (vía $k$) sino que además es muy compacto y también permite predecir de forma muy fácil para un usuario y/o para un item.\n",
    "\n",
    "*Nota: en rigor la matriz utilizada es $U^T$ para que cada vector de usuarios respete la convención de vector columna, pero por claridad y eficiencia se prefiere trabajar con la matriz traspuesta directamente. De la misma manera, $u_i$ considerará la fila $i$ de $U$ mientras que $v_j$ considerará la columna $j$ de $V$.*\n",
    "\n",
    "### La función objetivo\n",
    "\n",
    "Como todo modelo, para poder ajustarse a los datos se precisa una función objetivo a maximizar (o de pérdida a minimizar). En este caso se define la pérdida:\n",
    "\n",
    "$$\n",
    "J(U, V) = \\sum_{(i,j) \\in \\mathcal{O}} (r_{i,j} - u_i \\cdot v_j)^2 + \\lambda (||U||^2_2 + ||V||^2_2)\n",
    "$$\n",
    "\n",
    "que no es otra cosa que la suma de los errores cuadráticos (RSS) más una regularización por norma $\\ell_2$ de ambas matrices para prevenir overfitting.\n",
    "\n",
    "### ¿Cómo ajustar?\n",
    "\n",
    "Como es una función **no convexa** no podemos optimizar en forma directa sino que debemos recurrir a otros mecanismos aproximados.\n",
    "\n",
    "#### Opción 1: SGD (Stochastic Gradient Descent)\n",
    "\n",
    "El método de optimización sin restricciones por excelencia, en forma iterativa realiza el siguiente ciclo:\n",
    "\n",
    "1. Selecciona un rating observado $r_{i,j} / (i,j) \\in \\mathcal{O}$ al azar.\n",
    "2. Computa las derivadas $\\frac{dJ}{du_i},\\frac{dJ}{dv_j}$ de la pérdida $J$ respecto de $u_i$, $v_j$, evaluadas en los valores actuales.\n",
    "3. Realiza un paso de actualización $u_i^{t+1} = u_i^t - \\gamma \\cdot \\frac{dJ}{du_i}(u_i^t)$, $v_j^{t+1} = v_j^t - \\gamma \\cdot \\frac{dJ}{du_i}(v_j^t)$.\n",
    "\n",
    "Esto se realiza hasta un criterio de convergencia y para un *learning rate* $\\gamma > 0$.\n",
    "\n",
    "#### Opción 2: ALS (Alternating Least Squares)\n",
    "\n",
    "Este método se utiliza para optimizar objetivos de la forma $R = U \\cdot V$, y lo que se hace es iterativamente:\n",
    "\n",
    "1. Fijamos V, estimamos U por cuadrados mínimos para la ecuación $R = \\mathbf{U} \\cdot V$\n",
    "2. Fijamos U, estimamos V por cuadrados mínimos para la ecuación $R = U \\cdot \\mathbf{V}$\n",
    "\n",
    "Esto también se hace hasta un criterio de convergencia, que por ejemplo puede ser hasta que la norma de la diferencia en la actualización sea menor a una constante prefijada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-FlYs_t0HWg"
   },
   "source": [
    "## Un ejemplo de $R$\n",
    "\n",
    "![MF- matriz R.png](data:image/png;base64,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)\n",
    "\n",
    "En la imagen, si consideramos índices que inician en 0\n",
    "* $\\mathcal{O} = \\{(1,1), (1,3), (2,3), (4,4), (5,1), (5,6), (5,7), (6,3)\\}$\n",
    "* $\\mathcal{O}_{i=5} = \\{1,6,7\\}$\n",
    "* $\\mathcal{O}_{j=3} = \\{1,2,6\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b6G1bf6cOtn"
   },
   "source": [
    "## Resolviendo la pérdida por cuadrados mínimos para $U$\n",
    "\n",
    "Esto hay que hacerlo sí o sí por cada fila, dado que no se puede trabajar con la matriz completa $R$ ya que no es conocida. Planteemos el objetivo para un vector fila $u = u_i$:\n",
    "\n",
    "$$\n",
    "J(u) = \\sum_{j \\in \\mathcal{O}_i} (r_{i,j} - u \\cdot v_j)^2 + \\lambda ||u||^2\n",
    "$$\n",
    "\n",
    "\n",
    "donde $\\mathcal{O}_i = \\{j \\; / (i,j) \\in \\mathcal{O}\\}$, es decir los índices $j$ tal que, para un $i$ fijo, $(i,j) \\in \\mathcal{O}$.\n",
    "\n",
    "La derivada resulta:\n",
    "\n",
    "$$\n",
    "\\frac{dJ}{du} = -2 \\sum_{j \\in \\mathcal{O}_i} (r_{i,j} - u \\cdot v_j) \\cdot v_j^T + 2 \\lambda u\n",
    "$$\n",
    "\n",
    "\n",
    "*Nota: recordar que $||u||^2 = u^T \\cdot u$*.\n",
    "\n",
    "Ahora igualamos a 0 la derivada y despejamos $u$:\n",
    "\n",
    "$$\n",
    "-2 \\sum_{j \\in \\mathcal{O}_i} (r_{i,j} - u \\cdot v_j) \\cdot v_j^T + 2 \\lambda u = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "-2 \\sum_{j \\in \\mathcal{O}_i} r_{i,j} \\cdot v_j^T + 2 \\sum_{j \\in \\mathcal{O}_i} u \\cdot v_j \\cdot v_j^T   + 2 \\lambda u = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "u \\cdot (\\sum_{j \\in \\mathcal{O}_i} v_j \\cdot v_j^T + \\lambda I_k) = \\sum_{j \\in \\mathcal{O}_i} r_{i,j} \\cdot v_j^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "u^* =(\\sum_{j \\in \\mathcal{O}_i} r_{i,j} \\cdot v_j^T)  \\cdot (\\sum_{j \\in \\mathcal{O}_i} v_j \\cdot v_j^T + \\lambda I_k)^{-1}\n",
    "$$\n",
    "\n",
    "*Nota: observar que el anteúltimo renglón es una versión traspuesta del típico $A \\cdot x = b$, que es $x^T \\cdot A^T = b^T$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFBYt9kKonEO"
   },
   "source": [
    "## Ahora para $V$\n",
    "\n",
    "Utilizando una notación similar donde $\\mathcal{O}_j = \\{i \\; / (i,j) \\in \\mathcal{O}\\}$, la pérdida respecto de $v$ es:\n",
    "\n",
    "$$\n",
    "J(v) = \\sum_{i \\in \\mathcal{O}_j} (r_{i,j} - u_i \\cdot v)^2 + \\lambda ||v||^2\n",
    "$$\n",
    "\n",
    "Derivando respecto de $v$:\n",
    "\n",
    "$$\n",
    "\\frac{dJ}{dv} = -2 \\sum_{i \\in \\mathcal{O}_j} u_i^T \\cdot (r_{i,j} - u_i \\cdot v) + 2 \\lambda v\n",
    "$$\n",
    "\n",
    "Igualamos a 0 y despejamos igual que antes:\n",
    "\n",
    "$$\n",
    "(\\sum_{i \\in \\mathcal{O}_j} u_i^T \\cdot u_i + \\lambda I_k) \\cdot v = \\sum_{i \\in \\mathcal{O}_j}  u_i^T \\cdot r_{i,j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v^* = (\\sum_{i \\in \\mathcal{O}_j} u_i^T \\cdot u_i + \\lambda I_k)^{-1} \\cdot (\\sum_{i \\in \\mathcal{O}_j}  u_i^T \\cdot r_{i,j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-zOSXsLxeWD"
   },
   "source": [
    "## Código\n",
    "\n",
    "* El recomendador va a ser una clase\n",
    "  * Las matrices se tienen que poder observar como atributos\n",
    "* El criterio de convergencia va a llevar una función del tipo `f(U_old, V_old, U_new, V_new) -> Bool`\n",
    "* **NO** se va a hacer énfasis en la performance aunque la optimización sea completamente paralelizable, porque vuelve más difícil de leer el código (y Colab igual presta 1 solo core, así que...)\n",
    "* Se va a asumir que R es un dataframe con las columnas *user*, *item* y *rating*, donde *user* e *item* representan IDs que van desde 0 hasta n-1 y m-1 respectivamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1R6ePfBh4SvX"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from numpy.linalg import inv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IP8Xk-P06tX"
   },
   "outputs": [],
   "source": [
    "# MF class v2\n",
    "def ALS(U,V,R, O_is, O_js, lda, debug=True):\n",
    "  n, k = U.shape\n",
    "  k_, m = V.shape\n",
    "  assert k==k_, \"k doesn't match between U and V\"\n",
    "\n",
    "  # U pass\n",
    "  if debug:\n",
    "    print(f\"Solving for U\")\n",
    "  for i in range(n):\n",
    "    o_i = O_is[i]\n",
    "    r_v = np.zeros(shape=(1,k))\n",
    "    v_v_t = np.zeros(shape=(k, k))\n",
    "    for j in o_i:\n",
    "      v_j = V[:,j].reshape(-1,1)\n",
    "\n",
    "      # r_ij * v_j.T\n",
    "      r_v += R[(i,j)] * v_j.T\n",
    "\n",
    "      # v_j @ v_j.T\n",
    "      v_v_t += v_j @ v_j.T\n",
    "\n",
    "    U[i,:] = r_v @ inv(v_v_t + lda * np.identity(k))\n",
    "\n",
    "  # V pass\n",
    "  if debug:\n",
    "    print(f\"Solving for V\")\n",
    "  for j in range(m):\n",
    "    o_j = O_js[j]\n",
    "    r_u = np.zeros(shape=(k,1))\n",
    "    u_t_u = np.zeros(shape=(k, k))\n",
    "    for i in o_j:\n",
    "      u_i = U[i,:].reshape(1,-1)\n",
    "\n",
    "      # u_T * r_ij\n",
    "      r_u += u_i.T * R[(i,j)]\n",
    "\n",
    "      # u_T @ u\n",
    "      u_t_u += u_i.T @ u_i\n",
    "\n",
    "    # NumPy gets angry when we try to assign column vectors, so we need to flatten\n",
    "    V[:,j] = (\n",
    "        inv(u_t_u + lda * np.identity(k)) @ r_u\n",
    "              ).flatten()\n",
    "\n",
    "class MFModel:\n",
    "  def __init__(self, k, lda):\n",
    "    assert type(k)==int, k > 0\n",
    "    assert lda > 0\n",
    "    self.k = k\n",
    "    self.lda = lda\n",
    "\n",
    "  def fit(self, R_train, R_valid, rng_seed, iters, debug=True):\n",
    "    assert iters >= 2, \"Min iters can't be 1\"\n",
    "    # seed the rng\n",
    "    self.rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    # reset the historics\n",
    "    self.valid_mse_historic = []\n",
    "    self.train_loss_historic = []\n",
    "\n",
    "    # build some dicts for easier indexing\n",
    "    self._init_params(R_train)\n",
    "\n",
    "\n",
    "    # now run at most max_iters iterations of ALS\n",
    "    for i in range(iters):\n",
    "      if debug:\n",
    "        print(f\"Running iteration {i+1}/{iters}\")\n",
    "\n",
    "      ALS(self.U, self.V, self.R,\n",
    "          self.items_by_user, self.users_by_item,\n",
    "          self.lda, debug)\n",
    "\n",
    "      self.valid_mse_historic.append(self._estimate_MSE(R_valid, debug=debug))\n",
    "      self.train_loss_historic.append(self._loss(R_train, debug=debug))\n",
    "\n",
    "    return self\n",
    "\n",
    "  def _estimate_RSS(self, R, debug=True):\n",
    "    \"\"\"Estimate Residual Sum of Squares (RSS)\"\"\"\n",
    "    rss = 0.0\n",
    "    for user_id, item_id, rating in R.itertuples(index=False, name=None):\n",
    "      # predict value\n",
    "      y_hat = self.predict(user_id, item_id)\n",
    "\n",
    "      # add squared residual to total\n",
    "      rss += (y_hat - rating)**2\n",
    "    if debug:\n",
    "      print(f\"Estimated RSS is {rss:.3f}\")\n",
    "    return rss\n",
    "\n",
    "  def _estimate_MSE(self, R, debug=True):\n",
    "    # MSE = RSS / n\n",
    "    rows = R.shape[0]\n",
    "    mse = self._estimate_RSS(R,debug) / rows\n",
    "    if debug:\n",
    "      print(f\"Estimated MSE is {mse:.3f}\")\n",
    "    return mse\n",
    "\n",
    "  def _loss(self, R, debug=True):\n",
    "    # loss = RSS + lambda * (Frobenius(U)^2+Frobenius(V)^2)\n",
    "    U_norm_sqr = np.sum(self.U **2)\n",
    "    V_norm_sqr = np.sum(self.V **2)\n",
    "    loss = self._estimate_RSS(R,debug) + self.lda * (U_norm_sqr + V_norm_sqr)\n",
    "    if debug:\n",
    "      print(f\"U squared norm is {U_norm_sqr:.3f}, V squared norm is {V_norm_sqr:.3f}, loss is {loss:.3f}\")\n",
    "    return loss\n",
    "\n",
    "  def _init_params(self, R):\n",
    "    # if ids range from 0 to max_id, then max_id+1 is the number of unique elements\n",
    "    n = R[\"user\"].max() + 1\n",
    "    m = R[\"item\"].max() + 1\n",
    "\n",
    "    # build U, V matrices\n",
    "    self.U = self.rng.uniform(low=0,high=1/np.sqrt(self.k),size=(n,self.k))\n",
    "    self.V = self.rng.uniform(low=0,high=1/np.sqrt(self.k),size=(self.k,m))\n",
    "\n",
    "    # build the observed R values dict and dicts for O_i and O_j\n",
    "    self.R = dict()\n",
    "    self.items_by_user = defaultdict(lambda : [])\n",
    "    self.users_by_item = defaultdict(lambda : [])\n",
    "\n",
    "    # iterate once through the entire ratings\n",
    "    for user_id, item_id, rating in R.itertuples(index=False, name=None):\n",
    "      self.R[(user_id, item_id)] = rating\n",
    "      self.items_by_user[user_id].append(item_id)\n",
    "      self.users_by_item[item_id].append(user_id)\n",
    "\n",
    "  def predict(self, user_id, item_id):\n",
    "    # as simple as computing the inner product\n",
    "    # no need for reshaping in this case\n",
    "    return self.U[user_id,:] @ self.V[:, item_id]\n",
    "\n",
    "  def recommend(self, user_id, top_k=10):\n",
    "    # as simple as computing the product against the whole item matrix\n",
    "    # sorting and getting the top-k is just added functionality\n",
    "    estimated_ratings = self.U[user_id, :] @ self.V\n",
    "    known_items = self.items_by_user[user_id]\n",
    "\n",
    "    return [item_idx for item_idx in np.argsort(estimated_ratings)\n",
    "              if item_idx not in known_items][:-top_k-1:-1]\n",
    "\n",
    "  def summary(self):\n",
    "    print(\"Nº iter\\t\\tLoss(train)\\t\\tMSE(valid)\")\n",
    "    for idx, (train, valid) in enumerate(zip(self.train_loss_historic,\n",
    "                                             self.valid_mse_historic)):\n",
    "      print(f\"   {idx}\\t\\t{train:.4f}\\t\\t   {valid:.4f}\")\n",
    "\n",
    "  def plot_metrics(self, log_scale_train=False, log_scale_valid=False):\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "    values_valid = np.log10(self.valid_mse_historic) if log_scale_valid else self.valid_mse_historic\n",
    "    values_train = np.log10(self.train_loss_historic) if log_scale_train else self.train_loss_historic\n",
    "\n",
    "    iters = list(range(1,len(values_valid)+1))\n",
    "    ax.plot(iters, values_valid, 'o-', color='black', label='valid MSE')\n",
    "    ax.set_xlabel(\"Nº iteration\")\n",
    "    ax.set_ylabel(\"Validation-set MSE\", color='black')\n",
    "    ax.tick_params(axis='y', labelcolor='black')\n",
    "    ax.set_title(\"Metrics for fitted model (Loss on train, MSE on validation)\")\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylabel(\"Train-set Loss\",color='red')\n",
    "    ax2.plot(iters, values_train, 'o-', color='red', label='train loss')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "    return fig, ax, ax2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_hGsTgW-gzA"
   },
   "source": [
    "# Set de datos\n",
    "\n",
    "Vamos a utilizar el small dataset de [MovieLens](https://grouplens.org/datasets/movielens/latest/), que tiene 100.000 ratings de 9000 items para 600 usuarios (1 valor conocido cada 54).\n",
    "\n",
    "Podemos ver más abajo que cada fila representa un par (user, item) con su rating correspondiente, además del timestamp en que se realizó la puntuación pero eso no lo vamos a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eg1XvemXr8te",
    "outputId": "8bd2311c-45dc-48e0-facb-b52a2b561031"
   },
   "outputs": [],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip .\n",
    "!unzip ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T4zXa7pH-gOi",
    "outputId": "a0845136-f518-4e9c-8660-2a88eb146f73"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"./ml-latest-small/ml-latest-small/ratings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "nAeTqnEnmqQJ",
    "outputId": "387588b4-c791-4231-f42f-0f8b9b64c6c1"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acomodamos y separamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiEZkrdWIrOe",
    "outputId": "f9269788-54b4-427b-d91a-ed7e01653740"
   },
   "outputs": [],
   "source": [
    "rng_seed = 6552\n",
    "test_size = 0.3 # 30% para validacion\n",
    "df_train, df_valid = train_test_split(df,\n",
    "                                      test_size=test_size,\n",
    "                                      random_state=rng_seed)\n",
    "\n",
    "df_train.apply(lambda p: len(np.unique(p)), axis=0), df_valid.apply(lambda p: len(np.unique(p)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TKvQc1FOPuOi",
    "outputId": "cff39077-8564-49bf-f1a7-9eb3dccddbce"
   },
   "outputs": [],
   "source": [
    "# are all valid set users represented in the train set?\n",
    "train_users_set = set(df_train.userId.unique())\n",
    "len(df_valid[df_valid.userId.apply(lambda x: x in train_users_set)]), len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FOHciO1gT2m",
    "outputId": "0ea2a924-34ab-49cf-e42a-649b823be320"
   },
   "outputs": [],
   "source": [
    "# great! what about items?\n",
    "train_items_set = set(df_train.movieId.unique())\n",
    "len(df_valid[df_valid.movieId.apply(lambda x: x in train_items_set)]), len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ek3V3oAWfK7r",
    "outputId": "4fee837a-fdf2-4de2-8e48-f4adb813b6ab"
   },
   "outputs": [],
   "source": [
    "# dropping all \"new\" items since we couldn't train against them\n",
    "df_valid = df_valid[df_valid.movieId.apply(lambda x: x in train_items_set)]\n",
    "len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HEu6PM2QnDXs",
    "outputId": "9d098e9f-8f6c-4b76-ded0-4a2833fbecdf"
   },
   "outputs": [],
   "source": [
    "# are Ids complete? if so we can just do a linear mapping\n",
    "len(df_train[\"userId\"].unique()) == df_train[\"userId\"].max() , \\\n",
    "  len(df_train[\"movieId\"].unique()) == df_train[\"movieId\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Y1kwvm3a_x0Y",
    "outputId": "0cd2cf3b-e2dc-4f3a-f341-dec5459e1905"
   },
   "outputs": [],
   "source": [
    "# preprocess it so ids range from 0 to n-1 and m-1 (users, items respectively)\n",
    "\n",
    "mapping_items = {item_id: idx for idx, item_id in enumerate(df_train[\"movieId\"].unique())}\n",
    "\n",
    "R_train = pd.DataFrame({\n",
    "    \"user\": df_train[\"userId\"] - 1,\n",
    "    \"item\": [mapping_items[item_id] for item_id in df_train[\"movieId\"]],\n",
    "    \"rating\": df_train[\"rating\"]\n",
    "})\n",
    "\n",
    "R_valid = pd.DataFrame({\n",
    "    \"user\": df_valid[\"userId\"] - 1,\n",
    "    \"item\": [mapping_items[item_id] for item_id in df_valid[\"movieId\"]],\n",
    "    \"rating\": df_valid[\"rating\"]\n",
    "})\n",
    "\n",
    "R_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFyCZVsJvVUh",
    "outputId": "5a229c60-e71a-437a-fefd-b71655cbf4d1"
   },
   "outputs": [],
   "source": [
    "len(R_train[\"user\"].unique()) == R_train[\"user\"].max()+1, \\\n",
    "  len(R_train[\"item\"].unique()) == R_train[\"item\"].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqFG7FiAv6Q2",
    "outputId": "a2d6d1e5-a338-4120-9624-38172b8308c7"
   },
   "outputs": [],
   "source": [
    "# init the MF model\n",
    "model = MFModel(\n",
    "    k = 6,\n",
    "    lda = 8\n",
    ")\n",
    "\n",
    "# fit the model on train, validate on valid\n",
    "model.fit(\n",
    "    R_train = R_train,\n",
    "    R_valid = R_valid,\n",
    "    rng_seed = rng_seed,\n",
    "    iters = 9,\n",
    "    debug = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "_94Fw4b5wQ5w",
    "outputId": "a72d7144-af7d-479a-a101-797487d58b9c"
   },
   "outputs": [],
   "source": [
    "model.plot_metrics()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model overfitting\n",
    "In iteration 4 the validation MSE increases. The are 3 causes:\n",
    "\n",
    "- Big value for the k.\n",
    "- Small value for lambda.\n",
    "- Too much iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olGaRxyQZ_RM",
    "outputId": "0869f615-cef0-4d2c-d0e6-8ddb0ccfd039"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2h1J1FSH1Pk6",
    "outputId": "fa0f7d01-2037-4483-f8b6-c137d52f5cdb"
   },
   "outputs": [],
   "source": [
    "# a smaller model with k=4\n",
    "model_4 = MFModel(\n",
    "    k = 4,\n",
    "    lda = 5\n",
    ")\n",
    "\n",
    "model_4.fit(\n",
    "    R_train = R_train,\n",
    "    R_valid = R_valid,\n",
    "    rng_seed = rng_seed+5,\n",
    "    iters = 10,\n",
    ")\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "CWEbiriD1pEi",
    "outputId": "ecd64f77-0a34-440e-deaa-dbe9f039ef32"
   },
   "outputs": [],
   "source": [
    "model_4.plot_metrics()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jRNkFTdL4pp4",
    "outputId": "25e16252-a9da-437a-8880-e1f2596ad74d"
   },
   "outputs": [],
   "source": [
    "# read movies df\n",
    "movie_names = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
    "movie_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22qD7ewO3VSf",
    "outputId": "8e157bf2-ea2a-4ab4-f6eb-982510439deb"
   },
   "outputs": [],
   "source": [
    "# let's assume we're user 120\n",
    "some_user_id = 120\n",
    "\n",
    "recommended_item_id = model_4.recommend(some_user_id, top_k=5)\n",
    "recommended_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "eewA-j2R3h35",
    "outputId": "dda46f6a-dbe2-437e-aa55-937c923b66ad"
   },
   "outputs": [],
   "source": [
    "# let's see what we loved\n",
    "most_liked = df_train[df_train.userId == some_user_id+1].sort_values(by=\"rating\",ascending=False).head(10)\n",
    "most_liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "FbdymRxs5kI0",
    "outputId": "b5e1158c-1fab-4c96-906b-2267a4e05ab3"
   },
   "outputs": [],
   "source": [
    "# join by movie_name\n",
    "most_liked.set_index(\"movieId\").join(movie_names.set_index(\"movieId\")).loc[:,[\"title\", \"rating\", \"genres\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "Emq3SyU355h0",
    "outputId": "069c2f12-1a62-4ac3-cc50-8ad7beb5ab0f"
   },
   "outputs": [],
   "source": [
    "# get names for our recommendations\n",
    "movie_names.set_index(\"movieId\").iloc[recommended_item_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug_FiEdx56Ow"
   },
   "source": [
    "## Otra vuelta de rosca\n",
    "\n",
    "¿Qué pasa si queremos agregar *features* a medida para los usuarios y las peliculas en vez de simplemente $x=(user\\_id, item\\_id)$?\n",
    "\n",
    "Sea nuestro vector de features $x=(x_1, \\dots, x_n)$, un modelo lineal con interacciones de orden 2 sería:\n",
    "\n",
    "$$\n",
    "y \\approx w_0 + \\sum_{i=1}^n w_i \\cdot x_i + \\sum_{i=1}^n\\sum_{j=i+1}^n w_{i,j} \\cdot x_i \\cdot x_j\n",
    "$$\n",
    "\n",
    "Pero para un modelo con $n$ *features* para $x$, hay que estimar $1+n+\\frac{n(n+1)}{2} = \\frac{1}{2}n^2+\\frac{3}{2}n+1 = \\mathcal{O}(n^2)$, es decir, la cantidad de parámetros escala en forma cuadrática con la cantidad de features. Esto **no** es bueno porque vuelve al modelo mucho más complejo de lo que puede expresar, especialmente en un contexto en el que **las observaciones son escasas**.\n",
    "\n",
    "### Factorization Machines ([Paper](www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf))\n",
    "\n",
    "¿Y qué pasa si, al igual que con el rating, expresamos cada peso de la interacción como el producto interno de vectores latentes? Sea $V \\in \\mathbb{R}^{n \\times k}$, ahora el modelo es\n",
    "$$\n",
    "y \\approx w_0 + \\sum_{i=1}^n w_i \\cdot x_i + \\sum_{i=1}^n\\sum_{j=i+1}^n \\langle V_{i,:},V_{j,:}\\rangle \\cdot x_i \\cdot x_j\n",
    "$$\n",
    "\n",
    "y nuevamente la cantidad de parámetros es $1+n+kn = \\mathcal{O}(kn)$ lo cual vuelve a ser lineal respecto de la cantidad de features (y también de $k$!)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
